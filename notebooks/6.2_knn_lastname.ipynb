{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "311237c2",
   "metadata": {},
   "source": [
    "## Predict Race/Ethnicity from Unseen Last Name Using KNN (Cosine Distance)\n",
    "\n",
    "Using the Florida Voting Registration data, we build a knn classifier that predicts the ethnicity of an **unseen** name. We estimate distance between names using cosine distance across bi-char tokens of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96b61aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer                                                             \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31452866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Florida voter\n",
    "df = pd.read_csv('data/fl_2022_LastName.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "504427b4-72a6-4f8f-adc6-770f5f3540f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asian', 'hispanic', 'nh_black', 'nh_white', 'other']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races = sorted(df.race.unique().tolist())\n",
    "races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "997167ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.86 s, sys: 1.55 s, total: 10.4 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# build n-gram list\n",
    "NGRAMS = 2\n",
    "vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=.005, ngram_range=(NGRAMS, NGRAMS), lowercase=False) \n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "a = vect.fit_transform(df.name_last) \n",
    "tfidf = tfidf_transformer.fit_transform(a)\n",
    "\n",
    "vocab = vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "838ae1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ar', 'ru', ' B', 'Bi', 'it', 'ta', 'an', 'ng', ' D']\n",
      "num_words = 394\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for b in vocab:\n",
    "    c = vocab[b]\n",
    "    words.append((a[:, c].sum(), b))\n",
    "\n",
    "words_list = [w[1] for w in words]\n",
    "print(words_list[1:10])\n",
    "num_words = len(words_list)\n",
    "print(\"num_words = %d\" % num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb48932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(text, n):\n",
    "    a = zip(*[text[i:] for i in range(n)])\n",
    "    wi = []\n",
    "    for i in a:\n",
    "        w = ''.join(i)\n",
    "        try:\n",
    "            idx = words_list.index(w)\n",
    "        except:\n",
    "            idx = 0\n",
    "        wi.append(idx)\n",
    "    return wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1900bd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tfidf_index'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52af9fc5-9997-4c9a-939c-dad23dea1d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (953621, 11)\n",
      "Validation set size: (50191, 11)\n",
      "Test set size: (52833, 11)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=.05)\n",
    "train_df, valid_df = train_test_split(train_df, test_size=.05)\n",
    "\n",
    "train_df.reset_index(inplace=True)\n",
    "valid_df.reset_index(inplace=True)\n",
    "test_df.reset_index(inplace=True)\n",
    "\n",
    "print('Training set size: {}'.format(train_df.shape))\n",
    "print('Validation set size: {}'.format(valid_df.shape))\n",
    "print('Test set size: {}'.format(test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab48a8a0",
   "metadata": {},
   "source": [
    "## Find the best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e16b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Race Using Cosine Distance\n",
    "\n",
    "def predict_cosine_race(arg):\n",
    "    # reading the tuple passed on by the calling function\n",
    "    idx, row_data, test_df, corpus_df, corp_vector, k = arg\n",
    "    \n",
    "    # resizing the tf-idf (1, m) & corpus vectors to be (n, m)\n",
    "    #  n = number of samples\n",
    "    #  m = number of dimentions\n",
    "    orig_vector = tfidf[row_data['tfidf_index']].reshape(1, -1)\n",
    "\n",
    "    # calculating the cosine similarity beteween the name vector\n",
    "    #   and the corpus vectors.  Then filtering for only values\n",
    "    #   that are greater that what was passed on\n",
    "    cossim = cosine_similarity(orig_vector, corp_vector)\n",
    "        \n",
    "    # Order by cosine distance and pick top k\n",
    "    cossim_df = corpus_df.iloc[np.flip(cossim.flatten().argsort())[:k]]\n",
    "    \n",
    "    pred_race = cossim_df[races].mean().argmax()\n",
    "    test_df.loc[idx, 'pred_race'] = pred_race\n",
    "        \n",
    "    return pred_race\n",
    "\n",
    "def check_cosine_k(test_df, corpus_df, k):\n",
    "    results = []\n",
    "\n",
    "    num_cpu = mp.cpu_count() \n",
    "    pool = mp.pool.ThreadPool(processes=8)\n",
    "\n",
    "    corp_vector = tfidf[corpus_df['tfidf_index']]\n",
    "\n",
    "    # for idx, row in tqdm(test_df.iterrows()):\n",
    "    r = pool.map(predict_cosine_race, [(idx, row, test_df, corpus_df, corp_vector, k)\n",
    "                                for idx, row in test_df.iterrows()])\n",
    "    results.append(r)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "630eaee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_metrics = {\n",
    "    3:0,\n",
    "    5:0,\n",
    "    25:0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0a7e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_list = []\n",
    "for idx, row in valid_df.iterrows():\n",
    "    true_list.append(row['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f17a5f80-b08c-417b-bbbb-d4da0aa7abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement = {0: 'asian', 1: 'hispanic', 2: 'nh_black', 3: 'nh_white', 4: 'other'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efabb525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for value of k: 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.34      0.24      0.28      1657\n",
      "    hispanic       0.85      0.82      0.83     15573\n",
      "    nh_black       0.52      0.39      0.44      4974\n",
      "    nh_white       0.78      0.87      0.82     26644\n",
      "       other       0.16      0.05      0.08      1343\n",
      "\n",
      "    accuracy                           0.76     50191\n",
      "   macro avg       0.53      0.47      0.49     50191\n",
      "weighted avg       0.74      0.76      0.75     50191\n",
      "\n",
      "for value of k: 5 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.48      0.19      0.27      1657\n",
      "    hispanic       0.87      0.82      0.85     15573\n",
      "    nh_black       0.55      0.38      0.45      4974\n",
      "    nh_white       0.77      0.90      0.83     26644\n",
      "       other       0.20      0.04      0.06      1343\n",
      "\n",
      "    accuracy                           0.78     50191\n",
      "   macro avg       0.57      0.47      0.49     50191\n",
      "weighted avg       0.76      0.78      0.76     50191\n",
      "\n",
      "for value of k: 25 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.62      0.10      0.18      1657\n",
      "    hispanic       0.90      0.81      0.85     15573\n",
      "    nh_black       0.64      0.28      0.39      4974\n",
      "    nh_white       0.75      0.94      0.83     26644\n",
      "       other       0.41      0.01      0.02      1343\n",
      "\n",
      "    accuracy                           0.78     50191\n",
      "   macro avg       0.66      0.43      0.45     50191\n",
      "weighted avg       0.77      0.78      0.75     50191\n",
      "\n",
      "CPU times: user 16h 40min 2s, sys: 2h 19min, total: 18h 59min 2s\n",
      "Wall time: 3h 52min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for value, key in enumerate (k_metrics):\n",
    "    #print ('{} -- {}'.format(key, value))\n",
    "    result = check_cosine_k(valid_df, train_df, key)\n",
    "    \n",
    "    pred_list = np.array(result).reshape(-1)\n",
    "    pred_list = pred_list.tolist()\n",
    "    \n",
    "    true_list = pd.Series(true_list).replace(replacement).to_list()\n",
    "    pred_list = pd.Series(pred_list).replace(replacement).to_list()\n",
    "    \n",
    "    value = classification_report(true_list, pred_list, zero_division = 0)\n",
    "    \n",
    "    print ('for value of k: {} \\n{}'.format(key, value))\n",
    "    k_metrics[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318095e",
   "metadata": {},
   "source": [
    "## Test Set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f1c3f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 46min 16s, sys: 47min 32s, total: 6h 33min 48s\n",
      "Wall time: 1h 19min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = check_cosine_k(test_df, train_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "234698b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for value of k: 5 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.47      0.19      0.27      1812\n",
      "    hispanic       0.88      0.82      0.85     16243\n",
      "    nh_black       0.56      0.38      0.45      5145\n",
      "    nh_white       0.77      0.90      0.83     28183\n",
      "       other       0.22      0.04      0.07      1450\n",
      "\n",
      "    accuracy                           0.78     52833\n",
      "   macro avg       0.58      0.47      0.49     52833\n",
      "weighted avg       0.76      0.78      0.76     52833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_list = np.array(result).reshape(-1)\n",
    "pred_list = pred_list.tolist()\n",
    "\n",
    "true_list = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    true_list.append(row['race'])\n",
    "\n",
    "true_list = pd.Series(true_list).replace(replacement).to_list()\n",
    "pred_list = pd.Series(pred_list).replace(replacement).to_list()\n",
    "    \n",
    "value = classification_report(true_list, pred_list, zero_division = 0)\n",
    "\n",
    "print ('for value of k: {} \\n{}'.format(5, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56a76ef-c3fb-4898-ac82-af6987f97254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
