{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF ML Model (to aid basic interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Florida voter\n",
    "df = pd.read_csv(\"train_validation_test/fl_2022_fullname.csv.gz\",\n",
    "                 usecols=['full_name', 'race', 'race_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1803724, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stratified sample\n",
    "proto_df = df.groupby('race', group_keys=False).apply(lambda x: x.sample(frac=.2, random_state=10))\n",
    "proto_df.reset_index(inplace=True)\n",
    "proto_df.drop('index', axis=1, inplace=True)\n",
    "proto_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'asian', 1: 'hispanic', 2: 'nh_black', 3: 'nh_white', 4: 'other'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_id_df = proto_df[['race', 'race_code']].drop_duplicates().sort_values('race_code')\n",
    "race_to_id = dict(race_id_df.values)\n",
    "id_to_race = dict(race_id_df[['race_code', 'race']].values)\n",
    "id_to_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = proto_df.full_name\n",
    "y = proto_df.race_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1803724, 1338)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NGRAMS = 2\n",
    "#vect = TfidfVectorizer(analyzer='char', sublinear_tf=True, min_df=5, norm='l2', ngram_range=(1, NGRAMS), lowercase=False)\n",
    "vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=5, ngram_range=(1, NGRAMS), lowercase=False) \n",
    "\n",
    "features = vect.fit_transform(X).toarray()\n",
    "labels = y\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'asian':\n",
      "  . Most correlated bigrams:\n",
      "       . Zh\n",
      "       . g \n",
      "       . uy\n",
      "       . ng\n",
      "       . Ng\n",
      "# 'hispanic':\n",
      "  . Most correlated bigrams:\n",
      "       . ue\n",
      "       . o \n",
      "       . a \n",
      "       . z \n",
      "       . ez\n",
      "# 'nh_black':\n",
      "  . Most correlated bigrams:\n",
      "       . s \n",
      "       . sh\n",
      "       . z \n",
      "       . a \n",
      "       . o \n",
      "# 'nh_white':\n",
      "  . Most correlated bigrams:\n",
      "       . ue\n",
      "       . o \n",
      "       . a \n",
      "       . z \n",
      "       . ez\n",
      "# 'other':\n",
      "  . Most correlated bigrams:\n",
      "       . Bh\n",
      "       . aj\n",
      "       . ah\n",
      "       . ha\n",
      "       . Kh\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "N = 5\n",
    "for race_code, race in id_to_race.items():\n",
    "  features_chi2 = chi2(features, y == race_code)\n",
    "  indices = np.argsort(features_chi2[0])\n",
    "  feature_names = np.array(vect.get_feature_names_out())[indices]\n",
    "  bigrams = [v for v in feature_names if len(v) == 2]\n",
    "  print(\"# '{}':\".format(race))\n",
    "  print(\"  . Most correlated bigrams:\\n       . {}\".format('\\n       . '.join(bigrams[-N:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test dataset\n",
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)\n",
    "\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "feature_names = vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 4,\n",
    "                             max_samples  = .5, \n",
    "                             criterion    = 'entropy', \n",
    "                             random_state = 21)\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "X_test = vect.transform(X_test).toarray()\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Asian\n",
    "class_index = 0  \n",
    "result = permutation_importance(clf, vect.transform(X_train).toarray(), y_train == class_index, n_repeats=1, max_samples = 1000, random_state=42)\n",
    "\n",
    "# Get the feature importance scores\n",
    "importance_scores = result.importances_mean\n",
    "\n",
    "# Get the indices of features sorted by importance in descending order\n",
    "sorted_indices = importance_scores.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: C, Importance Score: 0.0012266436309883925\n",
      "Feature: ez, Importance Score: 0.0002266436309883925\n",
      "Feature: rr, Importance Score: 0.0002266436309883925\n",
      "Feature: gu, Importance Score: 0.0002266436309883925\n",
      "Feature: -, Importance Score: 0.0002266436309883925\n",
      "Feature: ma, Importance Score: 0.0002266436309883925\n",
      "Feature: n-, Importance Score: 0.0002266436309883925\n",
      "Feature: s , Importance Score: 0.0002266436309883925\n",
      "Feature: a , Importance Score: 0.0002266436309883925\n",
      "Feature:  J, Importance Score: 0.0002266436309883925\n",
      "Feature: Ce, Importance Score: 0.0002266436309883925\n",
      "Feature: ue, Importance Score: 0.0002266436309883925\n",
      "Feature: R , Importance Score: -0.0007733563690116075\n",
      "Feature: Si, Importance Score: -0.0007733563690116075\n",
      "Feature: Sc, Importance Score: -0.0007733563690116075\n",
      "Feature: Se, Importance Score: -0.0007733563690116075\n",
      "Feature: Sf, Importance Score: -0.0007733563690116075\n",
      "Feature: Sg, Importance Score: -0.0007733563690116075\n",
      "Feature: Sh, Importance Score: -0.0007733563690116075\n",
      "Feature: Qu, Importance Score: -0.0007733563690116075\n"
     ]
    }
   ],
   "source": [
    "# Print the feature importance scores and corresponding feature names\n",
    "for idx in sorted_indices[0:20]:\n",
    "    print(f\"Feature: {feature_names[idx]}, Importance Score: {importance_scores[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hispanic\n",
    "class_index = 1  \n",
    "result = permutation_importance(clf, vect.transform(X_train).toarray(), y_train == class_index, n_repeats=1, max_samples = 1000, random_state=42)\n",
    "\n",
    "# Get the feature importance scores\n",
    "importance_scores = result.importances_mean\n",
    "\n",
    "# Get the indices of features sorted by importance in descending order\n",
    "sorted_indices = importance_scores.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: A, Importance Score: 0.03821364413480721\n",
      "Feature: k, Importance Score: 0.03521364413480721\n",
      "Feature: a , Importance Score: 0.032213644134807234\n",
      "Feature: an, Importance Score: 0.032213644134807234\n",
      "Feature: K, Importance Score: 0.031213644134807234\n",
      "Feature: W, Importance Score: 0.031213644134807234\n",
      "Feature: ha, Importance Score: 0.031213644134807234\n",
      "Feature: ar, Importance Score: 0.031213644134807234\n",
      "Feature: ne, Importance Score: 0.030213644134807233\n",
      "Feature: n , Importance Score: 0.030213644134807233\n",
      "Feature: o , Importance Score: 0.030213644134807233\n",
      "Feature: z , Importance Score: 0.030213644134807233\n",
      "Feature: ll, Importance Score: 0.030213644134807233\n",
      "Feature: al, Importance Score: 0.030213644134807233\n",
      "Feature: ia, Importance Score: 0.029213644134807232\n",
      "Feature: do, Importance Score: 0.029213644134807232\n",
      "Feature: el, Importance Score: 0.029213644134807232\n",
      "Feature: w, Importance Score: 0.029213644134807232\n",
      "Feature: g , Importance Score: 0.02821364413480723\n",
      "Feature: g, Importance Score: 0.02821364413480723\n"
     ]
    }
   ],
   "source": [
    "# Print the feature importance scores and corresponding feature names\n",
    "for idx in sorted_indices[0:20]:\n",
    "    print(f\"Feature: {feature_names[idx]}, Importance Score: {importance_scores[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.37      0.26      0.31     10302\n",
      "    hispanic       0.69      0.72      0.70     65410\n",
      "    nh_black       0.49      0.42      0.45     53389\n",
      "    nh_white       0.78      0.84      0.80    221095\n",
      "       other       0.14      0.02      0.03     10549\n",
      "\n",
      "    accuracy                           0.71    360745\n",
      "   macro avg       0.49      0.45      0.46    360745\n",
      "weighted avg       0.69      0.71      0.70    360745\n",
      "\n",
      "[[  2712   1411    804   5159    216]\n",
      " [   828  46858   2204  15360    160]\n",
      " [   806   3224  22324  26771    264]\n",
      " [  2246  14743  18599 184948    559]\n",
      " [   765   1613   1609   6371    191]]\n"
     ]
    }
   ],
   "source": [
    "target_names = list(df.race.astype('category').cat.categories)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf, \"models/rf_fullname_interp.joblib\", compress=3)  # compression is ON!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
